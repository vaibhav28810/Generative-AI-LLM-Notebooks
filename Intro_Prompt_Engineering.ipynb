{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yixUjF0ciZc"
      },
      "source": [
        "### OpenAI Library, API Key and Helper Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_W3aYGpX7wg"
      },
      "source": [
        "Loading OpenAI Library and passing the API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3AQ6dFg0YlS1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28 python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PF5zx8yVX1By"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o7XizgJZ7Xu"
      },
      "source": [
        "Defining the helper function for OpenAI GPT 3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kKHsx2pKYkHq"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUFx0p3NaCQl"
      },
      "source": [
        "### Using delimiters - for indicating distinct parts:  ```, \"\"\", < >, <tag> </tag>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxNPsKQsYxZv",
        "outputId": "fcd30153-62bd-450f-f1a8-c9a3900e67ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is important to provide clear and specific instructions to guide a model towards the desired output and reduce the chances of receiving irrelevant or incorrect responses, even if it means writing a longer prompt for more clarity and context.\n"
          ]
        }
      ],
      "source": [
        "text = f\"\"\"\n",
        "You should express what you want a model to do by providing instructions that are as clear and specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, and reduce the chances of receiving irrelevant or incorrect responses. Don't confuse writing a \\\n",
        "clear prompt with writing a short prompt. In many cases, longer prompts provide more clarity and context for the model, which can lead to \\\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lpaKRNAatP6"
      },
      "source": [
        "### Generating structured Output - JSON/HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvuY8n-oY1qr",
        "outputId": "0fa30862-eb3d-497d-df0a-11c8009a95fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"movie_id\": 1,\n",
            "        \"title\": \"The Shawshank Redemption\",\n",
            "        \"director\": \"Frank Darabont\",\n",
            "        \"imdb_rating\": 9.3\n",
            "    },\n",
            "    {\n",
            "        \"movie_id\": 2,\n",
            "        \"title\": \"The Godfather\",\n",
            "        \"director\": \"Francis Ford Coppola\",\n",
            "        \"imdb_rating\": 9.2\n",
            "    },\n",
            "    {\n",
            "        \"movie_id\": 3,\n",
            "        \"title\": \"The Dark Knight\",\n",
            "        \"director\": \"Christopher Nolan\",\n",
            "        \"imdb_rating\": 9.0\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three movie titles with their directors and IMDb ratings.\n",
        "Provide them in JSON format with the following keys:\n",
        "movie_id, title, director, imdb_rating.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv63jPwhbAJB"
      },
      "source": [
        "### Asking the model to check whether conditions are satisfied\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzUuH4b6a8lI",
        "outputId": "1e705ac3-5a50-4de6-8cc4-d1f815116aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Crack eggs into a bowl and whisk until smooth.\n",
            "Step 2 - Heat a non-stick skillet over medium heat and add butter or oil.\n",
            "Step 3 - Pour beaten eggs into the skillet and let them cook undisturbed until edges begin to set.\n",
            "Step 4 - Use a spatula to push cooked edges towards the center while tilting the skillet.\n",
            "Step 5 - Add desired fillings such as cheese, vegetables, or meats.\n",
            "Step 6 - Fold the omelette in half using the spatula.\n",
            "Step 7 - Continue cooking for another minute until cheese melts and omelette is cooked through.\n",
            "Step 8 - Slide onto a plate and serve hot. Enjoy your delicious omelette!\n"
          ]
        }
      ],
      "source": [
        "text_1 = f\"\"\"\n",
        "To make an omelette, start by cracking eggs into a bowl and whisking them until smooth. Heat a non-stick \\\n",
        "skillet over medium heat and add a knob of butter or a drizzle of oil. \\Pour the beaten \\\n",
        "eggs into the skillet and let them cook undisturbed until the edges begin to \\\n",
        "set. Use a spatula to gently push the cooked edges toward the center while tilting the skillet to let the uncooked \\\n",
        "eggs flow to the edges. Once the omelette is mostly set but still slightly runny on top, add your desired fillings \\\n",
        "such as cheese, vegetables, or meats. Fold the omelette in half using the spatula, covering the fillings, and continue \\\n",
        "cooking for another minute until the cheese melts and the omelette is cooked through. Slide it onto a plate and serve \\\n",
        "hot. Enjoy your delicious omelette!\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q7_rERKbFHn",
        "outputId": "cfc2f46b-86f3-446d-96aa-243ece4a2db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completion for Text 2:\n",
            "No steps provided.\n"
          ]
        }
      ],
      "source": [
        "text_2 = f\"\"\"\n",
        "The sun is shining brightly today, and the birds are singing. It's a beautiful day to go for a walk in the park. The flowers are blooming, and the \\\n",
        "trees are swaying gently in the breeze. People are out and about, enjoying the lovely weather. Some are having picnics, while others are playing \\\n",
        "games or simply relaxing on the grass. It's a perfect day to spend time outdoors and appreciate the beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRRFhjgsbQ6j"
      },
      "source": [
        "### Few Shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovAM8A2kbOdN",
        "outputId": "2b4b76b1-f0e8-4303-a3e0-3d09468db99f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ": Resilience is the ability to bounce back from adversity, to withstand challenges and setbacks with strength and determination. Like a tree that bends but does not break in the face of a storm, resilience allows us to weather life's storms and emerge stronger on the other side. It is the inner strength that keeps us going when the going gets tough, the unwavering belief that we can overcome whatever obstacles come our way.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        ": Teach me about patience.\n",
        "\n",
        ": The river that carves the deepest valley flows from a modest spring; the grandest symphony originates from a single note; \\\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        ": Teach me about resilience.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xngrLWkpcthI"
      },
      "source": [
        "## Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT5HBrHKcyb9"
      },
      "source": [
        "**Text to Summarize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kU8WVWt0baUW"
      },
      "outputs": [],
      "source": [
        "prod_review = \"\"\"\n",
        "I recently received the XYZ Laptop, and I couldn't be happier with both the product and the service! \\\n",
        "Not only did the laptop arrive earlier than expected, but it has also proven to be worth every penny in terms \\\n",
        "of value. The build quality is exceptional, with a sturdy yet sleek design that exudes durability and \\\n",
        "professionalism. The performance is top-notch, handling all of my tasks with ease, from everyday browsing to \\\n",
        "demanding creative projects. The battery life exceeds my expectations, allowing me to work or enjoy entertainment \\\n",
        "for extended periods without needing to constantly search for an outlet. The display is vibrant and sharp, delivering \\\n",
        "an immersive viewing experience for movies, photos, and work presentations. Overall, the XYZ Laptop has surpassed \\\n",
        "my expectations in every aspect, and I'm extremely satisfied with my purchase. It's rare to find a product that not \\\n",
        "only arrives early but also offers such outstanding value for the price. I highly \\\n",
        "recommend this laptop to anyone in need of a reliable and high-quality computing solution.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmGCIm2rc9iZ"
      },
      "source": [
        "**Summarize with a word/sentence/character limit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSbBB3AIc7Uq",
        "outputId": "5ba0a7f0-ebe3-4e48-b78f-919b23aa9ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"The XYZ Laptop exceeded expectations with exceptional build quality, top-notch performance, long battery life, and vibrant display. Highly recommended for reliable computing.\"\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product review from an ecommerce site.\n",
        "\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1na3uWhAdG58"
      },
      "source": [
        "**Summarize with a focus on shipping and delivery**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw5W1EUXc_m6",
        "outputId": "9b58863c-d5c6-4e22-9e87-a5163f5ff3ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The customer was extremely pleased with the early delivery of the XYZ Laptop, praising its exceptional build quality, top-notch performance, and impressive battery life.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product review from an ecommerce site to give feedback to the Shipping deparmtment.\n",
        "\n",
        "Summarize the review below, delimited by triple backticks, in at most 30 words, and focusing on any aspects \\\n",
        "that mention shipping and delivery of the product.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UN1WC0ydLx8"
      },
      "source": [
        "**Summarize with focus on price and value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxef96DadEr5",
        "outputId": "6952cf16-0096-4951-b2b1-2ddfe37cb206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"The XYZ Laptop offers exceptional value for its price, with outstanding build quality, top-notch performance, long battery life, and vibrant display. Highly recommended for its reliability and quality.\"\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product review from an ecommerce site to give feedback to the \\\n",
        "pricing deparmtment, responsible for determining the price of the product.\n",
        "\n",
        "Summarize the review below, delimited by triple backticks, in at most 30 words, and focusing on any aspects \\\n",
        "that are relevant to the price and perceived value.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYqzy50adXxU"
      },
      "source": [
        "**Using Extract word instead of Summarize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHcpOO9KdLP7",
        "outputId": "0c3f9074-81af-40c2-d3f2-fff3f768efdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The laptop arrived earlier than expected, exceeding the customer's expectations. The product offers outstanding value for the price.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to extract relevant information from a product review from an ecommerce site to give \\\n",
        "feedback to the Shipping department.\n",
        "\n",
        "From the review below, delimited by triple quotes extract the information relevant to shipping and delivery. Limit to 30 words.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjsSFG4PdyD8"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "x9-zESPddUEh"
      },
      "outputs": [],
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KBgBSuId7C3"
      },
      "source": [
        "**Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSLxS-H5d5E3",
        "outputId": "0afe9c33-605c-44aa-9051-0ae16b598238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of the review is positive. The reviewer is satisfied with the lamp they purchased, mentioning the additional storage, fast delivery, good customer service, and ease of assembly. They also praise the company for their quick response to issues and overall care for their customers and products.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvcSVDUhd7xQ",
        "outputId": "1244bada-ff3c-4583-e8bc-799a75232dcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Give your answer as a single word, either \"positive\" \\\n",
        "or \"negative\".\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IN4JaYteCY6"
      },
      "source": [
        "**Identifying Emotions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry6VIIlnd_q4",
        "outputId": "31efaa07-858d-40a3-fd98-e4752850eb3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "happy, satisfied, grateful, impressed, content\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKv_AyBteHm0"
      },
      "source": [
        "**Anger**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq1aUvcMeCID",
        "outputId": "e9fd3606-f211-4520-de04-d8dbfbb0ebb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\\\n",
        "The review is delimited with triple backticks. \\\n",
        "Give your answer as either yes or no.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV7RnoWaeGa0",
        "outputId": "74919520-e486-4636-9550-2608fa9d5e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"Item\": \"lamp\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEWxo1-SeUFK",
        "outputId": "cd803c58-6cff-4bb7-d56a-6a0822b02650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"Sentiment\": \"positive\",\n",
            "    \"Anger\": false,\n",
            "    \"Item\": \"lamp\",\n",
            "    \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Sentiment (positive or negative)\n",
        "- Is the reviewer expressing anger? (true or false)\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "Format the Anger value as a boolean.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRep-cWGewkA"
      },
      "source": [
        "## Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjerdvU-eZpt",
        "outputId": "d8f5c345-3130-414e-8712-19fde61c983e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hola, me gustaría ordenar un omelette con jugo de naranja.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish: \\\n",
        "```Hi, I would like to order an omelette with orange juice```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6DXYo0yeyKq",
        "outputId": "37807d10-83be-4164-b648-9701d1e8d006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is French.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me which language this is:\n",
        "```Combien coûte le lampadaire?```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY8Be7eee6bu",
        "outputId": "f01c6f29-f18a-4c9d-9bcc-996323abd99b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "French: ```Salut, je voudrais commander une omelette avec du jus d'orange```\n",
            "\n",
            "Spanish: ```Hola, me gustaría pedir una tortilla con jugo de naranja```\n",
            "\n",
            "English pirate: ```Ahoy, I be wantin' to order a fine omelette with some orange grog```\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following  text to French and Spanish\n",
        "and English pirate: \\\n",
        "```Hi, I would like to order an omelette with orange juice```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rCHuy7ve_e4",
        "outputId": "e63252cb-2582-4af9-cfef-aca7b1bed079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formal: ¿Le gustaría ordenar una almohada?\n",
            "Informal: ¿Te gustaría ordenar una almohada?\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following text to Spanish in both the \\\n",
        "formal and informal forms:\n",
        "'Would you like to order a pillow?'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1TfsYY1fVVH"
      },
      "source": [
        "**Multi-lingual translation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VSny7GkfDg0",
        "outputId": "d9c78d85-f087-4527-9b69-d40111397af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original message (This is French.): La performance du système est plus lente que d'habitude.\n",
            "English: \"The system performance is slower than usual.\"\n",
            "\n",
            "Korean: \"시스템 성능이 평소보다 느립니다.\" \n",
            "\n",
            "Original message (This is Spanish.): Mi monitor tiene píxeles que no se iluminan.\n",
            "English: \"My monitor has pixels that do not light up.\"\n",
            "Korean: \"내 모니터에는 밝아지지 않는 픽셀이 있습니다.\" \n",
            "\n",
            "Original message (Italian): Il mio mouse non funziona\n",
            "English: My mouse is not working\n",
            "Korean: 내 마우스가 작동하지 않습니다. \n",
            "\n",
            "Original message (This is Polish.): Mój klawisz Ctrl jest zepsuty\n",
            "English: My Ctrl key is broken\n",
            "Korean: 제 Ctrl 키가 고장 났어요 \n",
            "\n",
            "Original message (This is Chinese.): 我的屏幕在闪烁\n",
            "English: My screen is flickering\n",
            "Korean: 내 화면이 깜박거립니다 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_messages = [\n",
        "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal\n",
        "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
        "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
        "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
        "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
        "]\n",
        "\n",
        "for issue in user_messages:\n",
        "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
        "    lang = get_completion(prompt)\n",
        "    print(f\"Original message ({lang}): {issue}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Translate the following  text to English \\\n",
        "    and Korean: ```{issue}```\n",
        "    \"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj0aN38tfSkT"
      },
      "source": [
        "**Tone Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-xQurY3fI4O",
        "outputId": "2ad728fa-b40c-4eac-97f8-b26e23360426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dear Sir/Madam,\n",
            "\n",
            "I am writing to bring to your attention the specifications of a standing lamp that I believe may be of interest to you. \n",
            "\n",
            "Sincerely,\n",
            "Joe\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following from slang to a business letter:\n",
        "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPWKOpbXfc4c"
      },
      "source": [
        "**Formatting Conversion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvZ5zNigfZbv",
        "outputId": "70023358-8d75-4bb5-ae0d-7af23bc0de03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<html>\n",
            "<head>\n",
            "    <title>Restaurant Employees</title>\n",
            "</head>\n",
            "<body>\n",
            "    <table border=\"1\">\n",
            "        <tr>\n",
            "            <th>Name</th>\n",
            "            <th>Email</th>\n",
            "        </tr>\n",
            "        <tr>\n",
            "            <td>Shyam</td>\n",
            "            <td>shyamjaiswal@gmail.com</td>\n",
            "        </tr>\n",
            "        <tr>\n",
            "            <td>Bob</td>\n",
            "            <td>bob32@gmail.com</td>\n",
            "        </tr>\n",
            "        <tr>\n",
            "            <td>Jai</td>\n",
            "            <td>jai87@gmail.com</td>\n",
            "        </tr>\n",
            "    </table>\n",
            "</body>\n",
            "</html>\n"
          ]
        }
      ],
      "source": [
        "data_json = { \"resturant employees\" :[\n",
        "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
        "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
        "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
        "]}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following python dictionary from JSON to an HTML \\\n",
        "table with column headers and title: {data_json}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "DbLgFQOefeHH",
        "outputId": "1dd81d37-def5-4be2-87bf-fe10103efd58"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head>\n",
              "    <title>Restaurant Employees</title>\n",
              "</head>\n",
              "<body>\n",
              "    <table border=\"1\">\n",
              "        <tr>\n",
              "            <th>Name</th>\n",
              "            <th>Email</th>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>Shyam</td>\n",
              "            <td>shyamjaiswal@gmail.com</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>Bob</td>\n",
              "            <td>bob32@gmail.com</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>Jai</td>\n",
              "            <td>jai87@gmail.com</td>\n",
              "        </tr>\n",
              "    </table>\n",
              "</body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
        "display(HTML(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIRGbNppfkr7"
      },
      "source": [
        "**Spelling andGrammar Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj4pnkf4ff0g",
        "outputId": "b9c4ff10-8533-482a-a07b-d19b36530284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got this for my daughter for her birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. One of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think there might be other options that are bigger for the same price. It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n"
          ]
        }
      ],
      "source": [
        "text = f\"\"\"\n",
        "Got this for my daughter for her birthday cuz she keeps taking \\\n",
        "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
        "it everywhere with her, and it's super soft and cute.  One of the \\\n",
        "ears is a bit lower than the other, and I don't think that was \\\n",
        "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
        "though. I think there might be other options that are bigger for \\\n",
        "the same price.  It arrived a day earlier than expected, so I got \\\n",
        "to play with it myself before I gave it to my daughter.\n",
        "\"\"\"\n",
        "prompt = f\"proofread and correct this review: ```{text}```\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em2hAq65fnqY",
        "outputId": "443b4ac2-0699-46a9-ed5c-70a522c0895f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting redlines\n",
            "  Downloading redlines-0.4.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from redlines) (8.1.7)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.3.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from redlines) (13.7.0)\n",
            "Collecting rich-click<2.0.0,>=1.6.1 (from redlines)\n",
            "  Downloading rich_click-1.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich<14.0.0,>=13.3.5->redlines) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sachintripathi/Library/Python/3.11/lib/python/site-packages (from rich<14.0.0,>=13.3.5->redlines) (2.17.2)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich-click<2.0.0,>=1.6.1->redlines) (4.8.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.3.5->redlines) (0.1.2)\n",
            "Downloading redlines-0.4.2-py3-none-any.whl (8.0 kB)\n",
            "Downloading rich_click-1.7.3-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: rich-click, redlines\n",
            "Successfully installed redlines-0.4.2 rich-click-1.7.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install redlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "XFucOkeagANm",
        "outputId": "d8d28b65-5cdb-41db-ca02-dd8f5d9f38d6"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Got this for my daughter for her birthday <span style='color:red;font-weight:700;text-decoration:line-through;'>cuz </span><span style='color:green;font-weight:700;'>because </span>she keeps taking mine from my <span style='color:red;font-weight:700;text-decoration:line-through;'>room.  </span><span style='color:green;font-weight:700;'>room. </span>Yes, adults also like pandas <span style='color:red;font-weight:700;text-decoration:line-through;'>too.  </span><span style='color:green;font-weight:700;'>too. </span>She takes it everywhere with her, and it's super soft and <span style='color:red;font-weight:700;text-decoration:line-through;'>cute.  </span><span style='color:green;font-weight:700;'>cute. </span>One of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think there might be other options that are bigger for the same <span style='color:red;font-weight:700;text-decoration:line-through;'>price.  </span><span style='color:green;font-weight:700;'>price. </span>It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from redlines import Redlines\n",
        "\n",
        "diff = Redlines(text,response)\n",
        "display(Markdown(diff.output_markdown))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "dgx68jCdgGtY",
        "outputId": "fd8d8360-2e9e-4650-88a9-e6386130c6b3"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "I purchased this adorable panda plush as a birthday gift for my daughter, as she kept borrowing mine from my room. It's not just for kids - adults can appreciate the charm of pandas too. The plush is incredibly soft and cute, and my daughter loves taking it everywhere with her. However, I did notice that one of the ears is slightly lower than the other, which seems unintentional. Additionally, I found the size to be a bit smaller than expected given the price. I believe there may be larger options available for the same cost. Despite this, the plush arrived a day earlier than anticipated, allowing me to enjoy it myself before gifting it to my daughter. Overall, while there are some minor flaws, the quality and cuteness of this panda plush make it a worthwhile purchase for any panda enthusiast."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "proofread and correct this review. Make it more compelling.\n",
        "Ensure it follows APA style guide and targets an advanced reader.\n",
        "Output in markdown format.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlTPXWn8gafm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
