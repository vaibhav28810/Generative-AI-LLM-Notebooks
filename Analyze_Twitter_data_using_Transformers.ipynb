{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7bf9b2b7f5d43719cc2b226799fe46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd5ad539cc0b4627959be27583b99161",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_591e24fa78f843e48d31ab779c4ccc95",
              "IPY_MODEL_a306629c1c9e45d8b5539e7f0b3e3f4b"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "bd5ad539cc0b4627959be27583b99161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "591e24fa78f843e48d31ab779c4ccc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a540eb0458fc4b09855a305912587d93",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a892758ae1746e6b753488c964deb00"
          },
          "model_module_version": "1.5.0"
        },
        "a306629c1c9e45d8b5539e7f0b3e3f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_181186135e6a454699ada9b26f3761f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 119kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04b025c6cf0640eb9b472620e2f0fbd4"
          },
          "model_module_version": "1.5.0"
        },
        "a540eb0458fc4b09855a305912587d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "5a892758ae1746e6b753488c964deb00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "181186135e6a454699ada9b26f3761f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "04b025c6cf0640eb9b472620e2f0fbd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "d709854fb297465380b42c50a0b084d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92c9047de1d64f74b5edaa9a5d425865",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4fdf469593e043ca8416ae98b3bb5baa",
              "IPY_MODEL_46d55661ef574cd2bbb37ade381663f2"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "92c9047de1d64f74b5edaa9a5d425865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "4fdf469593e043ca8416ae98b3bb5baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34cceeb4e4a54a9f812a1efad269b508",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_530063e621bc4d668d8668cecbd49a3b"
          },
          "model_module_version": "1.5.0"
        },
        "46d55661ef574cd2bbb37ade381663f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28948bc569184b53a5bdc4d4641905c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 41.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_311d23a1002340d8af7bfa94eb7194bd"
          },
          "model_module_version": "1.5.0"
        },
        "34cceeb4e4a54a9f812a1efad269b508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "530063e621bc4d668d8668cecbd49a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "28948bc569184b53a5bdc4d4641905c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "311d23a1002340d8af7bfa94eb7194bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "3339ca2ba8624784a1f85cdb2823ade0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b26d4a07e8e47d0a8d0a4daaaaa0c0f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_152dfdb886b64fb18a4394f11d48a5a1",
              "IPY_MODEL_073d25c6ea9143abb394c0cc1def578e"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "2b26d4a07e8e47d0a8d0a4daaaaa0c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "152dfdb886b64fb18a4394f11d48a5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0da22870c9045d293e202670c507886",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b4f9faac853431faf29f22c5d9b826c"
          },
          "model_module_version": "1.5.0"
        },
        "073d25c6ea9143abb394c0cc1def578e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b2a97ba191f4dc3832383d451d04977",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.89MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d00dd99aca304796b580a68afdc77e76"
          },
          "model_module_version": "1.5.0"
        },
        "f0da22870c9045d293e202670c507886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "4b4f9faac853431faf29f22c5d9b826c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "8b2a97ba191f4dc3832383d451d04977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "d00dd99aca304796b580a68afdc77e76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4kDQK1IIzsN"
      },
      "source": [
        "# **BERT to Analyze Twitter Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY95J4PWJu2y"
      },
      "source": [
        "In this session, we will talk about the working of BERT along with the different methodologies involved and will implement twitter sentiment analysis using the BERT model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-bejPe_Jyg1"
      },
      "source": [
        "To read about it more, please go through [this](https://analyticsindiamag.com/how-i-used-bidirectional-encoder-representations-from-transformers-bert-to-analyze-twitter-data/) article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IFGB9rNKd2a"
      },
      "source": [
        "## **Implementation of BERT to Analyze Twitter Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf3lWqeQKhNm"
      },
      "source": [
        "Let us consider a simple dataset like twitter sentiment analysis data for the implementation of BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJjFA_ihKi6R"
      },
      "source": [
        "Checking for GPU :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzqx6kovHpGl",
        "outputId": "4688dab8-f7d1-4f3c-a125-3a950ce4edfb"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "else:\n",
        "    print('Using CPU.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly__RwrOKnvN"
      },
      "source": [
        "Installing the transformer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ex7A7yfKrQW",
        "outputId": "9f3c37f1-ca54-4411-9d72-6c6f58198eab"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.9MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UeRmBDWKqhR"
      },
      "source": [
        "Loading the data and converting it to NumPy array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ryCKPOCLSzK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tweet_train=pd.read_csv('https://raw.githubusercontent.com/MohamedAfham/Twitter-Sentiment-Analysis-Supervised-Learning/master/Data/train_tweets.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89ZJSR9gLWGg"
      },
      "source": [
        "tweets = tweet_train.tweet.values\n",
        "labels = tweet_train.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st_X7mh_LacP"
      },
      "source": [
        "Now, we will initialize the BERT tokenizer and convert each word to a unique token. Here we use a method called encode which helps in combining multiple steps. The method splits the sentences to tokens, adds the [cls] and [sep] tokens and also matches the tokens to id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206,
          "referenced_widgets": [
            "e7bf9b2b7f5d43719cc2b226799fe46b",
            "bd5ad539cc0b4627959be27583b99161",
            "591e24fa78f843e48d31ab779c4ccc95",
            "a306629c1c9e45d8b5539e7f0b3e3f4b",
            "a540eb0458fc4b09855a305912587d93",
            "5a892758ae1746e6b753488c964deb00",
            "181186135e6a454699ada9b26f3761f3",
            "04b025c6cf0640eb9b472620e2f0fbd4",
            "d709854fb297465380b42c50a0b084d8",
            "92c9047de1d64f74b5edaa9a5d425865",
            "4fdf469593e043ca8416ae98b3bb5baa",
            "46d55661ef574cd2bbb37ade381663f2",
            "34cceeb4e4a54a9f812a1efad269b508",
            "530063e621bc4d668d8668cecbd49a3b",
            "28948bc569184b53a5bdc4d4641905c0",
            "311d23a1002340d8af7bfa94eb7194bd",
            "3339ca2ba8624784a1f85cdb2823ade0",
            "2b26d4a07e8e47d0a8d0a4daaaaa0c0f",
            "152dfdb886b64fb18a4394f11d48a5a1",
            "073d25c6ea9143abb394c0cc1def578e",
            "f0da22870c9045d293e202670c507886",
            "4b4f9faac853431faf29f22c5d9b826c",
            "8b2a97ba191f4dc3832383d451d04977",
            "d00dd99aca304796b580a68afdc77e76"
          ]
        },
        "id": "gyBhd0gjLcRO",
        "outputId": "12b65c76-7751-4be4-f62b-9a9871eb457a"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tweetid = []\n",
        "for tweet in tweets:\n",
        "  encoded_tweet = tokenizer.encode(tweet,add_special_tokens = True,)\n",
        "  tweetid.append(encoded_tweet)\n",
        "\n",
        "print('Original: ', tweets[0])\n",
        "print('Token IDs:', tweetid[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7bf9b2b7f5d43719cc2b226799fe46b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d709854fb297465380b42c50a0b084d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3339ca2ba8624784a1f85cdb2823ade0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run\n",
            "Token IDs: [101, 1030, 5310, 2043, 1037, 2269, 2003, 28466, 2389, 1998, 2003, 2061, 14337, 2002, 8011, 2015, 2010, 4268, 2046, 2010, 28466, 1012, 1001, 2448, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9C7jVXYLhkb"
      },
      "source": [
        "Next, we will truncate the sentences so that all the sentences have the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RTXYI9ZLn3s",
        "outputId": "f9ce259a-0188-4aea-f620-27719434a35f"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 64\n",
        "print('\\n Truncating all sentences to %d values...' % MAX_LEN)\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "tweetid = pad_sequences(tweetid, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrOvH2DcLuWV"
      },
      "source": [
        "The final step before the training begins is to create masks in the input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMJyTfXVLwhe"
      },
      "source": [
        "masks = []\n",
        "for tweet in tweetid:\n",
        "  mask = [int(token_id > 0) for token_id in tweet]\n",
        "  masks.append(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZCri8NvL2dJ"
      },
      "source": [
        "Let us first split the data into training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PQZS0y2L8Oe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(tweetid, labels, random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(masks, labels, random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYt3ggIgL-8O"
      },
      "source": [
        "Now, since we are implementing this in PyTorch we will convert the data into tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAEshBYUMBml"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h06pDdpkMDuw"
      },
      "source": [
        "We will use the pre-trained BERT sequence classifier model on our data and Adam optimizer. We will set the learning rate to a very small value and initialize a scheduler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg4TKtRIMGak",
        "outputId": "a7bef431-8657-4e3b-d87e-4438bfbdca56"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cpu()\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0TDz_zdMK8I"
      },
      "source": [
        "Training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omWmr4KCMVr2",
        "outputId": "aa34d5d4-68fa-4bb9-e928-9820241243b6"
      },
      "source": [
        "def accuracy(preds, labels):\n",
        "    pred = np.argmax(preds, axis=1).flatten()\n",
        "    labels = labels.flatten()\n",
        "    return np.sum(pred == labels) / len(labels)\n",
        "\n",
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "for epoch_i in range(0, epochs):\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "  total_loss = 0\n",
        "  model.train()\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}. '.format(step, len(train_dataloader)))\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    outputs = model(b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels)\n",
        "\n",
        "    loss = outputs[0]\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"validation\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.00\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Batch    50  of    899. \n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.01\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Batch   100  of    899. \n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.02\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Batch   150  of    899. \n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.03\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Batch   200  of    899. \n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.04\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Batch   250  of    899. \n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Batch   300  of    899. \n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.05\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Batch   350  of    899. \n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.06\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Batch   400  of    899. \n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Batch   450  of    899. \n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.07\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Batch   500  of    899. \n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Batch   550  of    899. \n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.08\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Batch   600  of    899. \n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.09\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Batch   650  of    899. \n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Batch   700  of    899. \n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.10\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Batch   750  of    899. \n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Batch   800  of    899. \n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.11\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Batch   850  of    899. \n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n",
            "  Average training loss: 0.12\n",
            "validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maLkT663MbrC"
      },
      "source": [
        "#Graph:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "plt.plot(loss_values, 'b-o')\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "BERT to Analyze Twitter Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![4-2.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "aY2YakJqcOpN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lGomjXRMhD3"
      },
      "source": [
        "The results indicate that the accuracy for the BERT model is 97% which means the model performed well even on small datasets. The model has not overfitted as we can see no sharp spike in the graph shown above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ujR2juKMmJf"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWdDmcFBMo73"
      },
      "source": [
        "Let us see how our model performed on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og8EPHO4MsOd"
      },
      "source": [
        "tweet_test=pd.read_csv('https://raw.githubusercontent.com/bhoomikamadhukar/NLP/master/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbYwp8X8MyCh"
      },
      "source": [
        "We will have to perform the same processing techniques as we did for training here as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-qMOoicM3VN"
      },
      "source": [
        "tweetvalidation = tweet_test.tweet.values\n",
        "labels=tweet_test.label.values\n",
        "test_id = []\n",
        "\n",
        "for tweet in tweetvalidation:\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet,\n",
        "                        add_special_tokens = True,\n",
        "                   )\n",
        "    test_id.append(encoded_tweet)\n",
        "test_id = pad_sequences(test_id, maxlen=MAX_LEN,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = []\n",
        "for seq in test_id:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "prediction_inputs = torch.tensor(test_id)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "batch_size = 32\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_flattening = np.argmax(predictions[i], axis=1).flatten()\n",
        "print(classification_report(true_labels[0], pred_labels_flattening) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_cUOUWbM7Ey"
      },
      "source": [
        "Thus we can see that within a short period of time we can build a BERT model that works on test data with a fairly good score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prpNOPgzWgiU"
      },
      "source": [
        "# **Related Articles:**\n",
        "\n",
        "> * [BERT to Analyze Twitter Data ](https://analyticsindiamag.com/how-i-used-bidirectional-encoder-representations-from-transformers-bert-to-analyze-twitter-data/)\n",
        "\n",
        "> * [Language Modelling using Unigram](https://analyticsindiamag.com/complete-guide-on-language-modelling-unigram-using-python/)\n",
        "\n",
        "> * [Predict the News Category](https://analyticsindiamag.com/guide-to-cracking-machinehacks-predict-the-news-category-hackathon/)\n",
        "\n",
        "> * [Guide to Sense2vec](https://analyticsindiamag.com/guide-to-sense2vec-contextually-keyed-word-vectors-for-nlp/)\n",
        "\n",
        "> * [Download Twitter Data and Analyze](https://analyticsindiamag.com/hands-on-guide-to-download-analyze-and-visualize-twitter-data/)\n",
        "\n",
        "> * [Sentiment Analysis using LSTM](https://analyticsindiamag.com/how-to-implement-lstm-rnn-network-for-sentiment-analysis/)"
      ]
    }
  ]
}